{"componentChunkName":"component---src-templates-blog-post-js","path":"/design-ml-library/","result":{"data":{"markdownRemark":{"html":"<p>This article is an attempt to think about all the various activities in\na deep-learning based ML model development process and to distill those\ninto a high-level functional and object-oriented design library based on\nthe PyTorch framework.</p>\n<p>At a high level, the process of ML model development for a single task\ncan be subdivided into the following stages</p>\n<ol>\n<li>Data Setup and Feature Preprocessing: perhaps multiple datasets,\naugmentations,</li>\n<li>Model and Objective/Loss Specification: specified in code in PyTorch</li>\n<li>Model Training: optimization</li>\n<li>Performance Evaluation: performance metrics on validation set, test\nset</li>\n</ol>\n<p>The goals of the new high-level library would be to support and simplify</p>\n<ol>\n<li>Model specification: modular ability to combine multiple models like\nlegos</li>\n<li>Loss-function specification and tuning: each layer can have\ndifferent and multiple objectives, can arrive from models themselves</li>\n<li>Model deployment tools: quantization, factorization, ONNX etc.</li>\n<li>Self-supervised learning and coupled with data augmentation: support\nfor online self-supervised learning, test-time self-supervised\nlearning</li>\n<li>Multi-task learning: train on multiple datasets and tasks. Some\ntasks can share common representations and have task specific\nbranches subsequent to that</li>\n<li>Curriculum learning: a teacher (RL agent, perhaps) figures out\nsequence of tasks and examples within those tasks to learn better\nrepresentations and/or perform better at tasks</li>\n<li>Multi-mode learning: when inputs are from two or more different\ndomains (like audio, sensors, video, images, etc.) and ability to\nshare/relate representations of same object</li>\n<li>ML model debugging: feature attribution, hard examples,\nout-of-domain indicators</li>\n<li>Model report card</li>\n</ol>\n<p>Let’s take all of these goals and then try to create an example that\nallow easy use and expression of high-level ideas quickly.</p>\n<h2>High-level example using JumpML library</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import jumpml\nimport torch.optim as optim\n\n# datasetFile defines\n#         multiple datasets, train, test, validation splits\n#         feature processing pipelines (could include pretrained models themselves)\n#         transformations and augmentations\n#         curriculum learning options\ndataloader = jumpml.createDataloader(datasetFile)\n\n# modelFile defines\n#          pytorch modules and connections\n#          objective functions at/between layers/nodes\nmodel = jumpml.loadModel(modelFile)\n\n# define optimizer as usual.\noptimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n\n# Create Learner based on learnerOptions\n#          initialization, EMA parameters, EWC, parameter saving\n#          self-supervised learning phases\n#          curriculum learning based on learning\n#          dynamic model augmentation: adding more capacity or branches dynamically\n#         logging learning progress\nlearner = jumpml.createLearner(dataloader, model, optimizer, learnerOptions)\n\n# Self-supervised phase\nlearner.ssLearn()\n\n# Supervised Learning Phase: perhaps trains only the task-specific layers... may be does some multi-task learning on some other layers.\nfor epochs in range(numEpochs):\n    learner.trainEpoch()  # this could only impact the classifier branches\n\n\n# Evaluation\n# evalMetrics are a list of functions.\n# each function takes model predictions, ground truth and calculates metrics\nevalResults = jumpml.evalModel(dataloader, model, evalMetrics)\n\n# Reports, visualization, deployment\n# may run a separate distillation loop (quantization, factorization, onnx exporting)\njumpml.deployModel(evalResults, model, deploymentConfig)</code></pre></div>","excerpt":"This article is an attempt to think about all the various activities in\na deep-learning based ML model development process and to distill those\ninto a high…","frontmatter":{"title":"Design of a high-level PyTorch ML library","date":"2020-07-30T00:00:00.000Z","subject":["pytorch","ml","sw","design","opensource"],"author":"RSP","featimg":null},"fields":{"slug":"/design-ml-library/","readingTime":{"text":"3 min read"}}},"site":{"siteMetadata":{"title":"JumpML"}}},"pageContext":{"slug":"/design-ml-library/"}}}