{"componentChunkName":"component---src-templates-blog-post-js","path":"/howto-pytorch-c++/output/","result":{"data":{"markdownRemark":{"html":"<p>In this post we will go through the steps of running a pre-trained PyTorch model in C++ on MacOS (or other platform where you can compile C/C++). The steps are as follows</p>\n<ol>\n<li>Convert PyTorch model (.pt file) to a TorchScript ScriptModule</li>\n<li>Serialize the the Script Module to a file</li>\n<li>Load the Script Module in C++</li>\n<li>Build/Make the C++ application using CMake</li>\n</ol>\n<p>This follows the official <a href=\"https://pytorch.org/tutorials/advanced/cpp_export.html\">PyTorch tutorial</a> but is adapted to our Speech Commands Recognition model.</p>\n<p>Why would we want to do something like this? There could be several reasons</p>\n<ol>\n<li>Speed: C/C++ is known to be faster</li>\n<li>Memory footprint: Python is not famous for memory footprint use</li>\n<li>Targeting Edge ML (embedded systems) which don’t have a lot of memory or CPU horsepower</li>\n<li>Integrating into a native app (iOS or MacOS)</li>\n<li>Production cloud service</li>\n</ol>\n<h2>Convert PyTorch model (.pt file) to a TorchScript ScriptModule</h2>\n<h3>What is TorchScript?</h3>\n<p>An intermediate representation of a PyTorch model that can be run in C++. We can obtain TorchScript of a PyTorch model (subclass of nn.Module) by</p>\n<ol>\n<li>Tracing an existing module</li>\n<li>Use scripting to directly compile a module</li>\n</ol>\n<p>Tracing is accomplished by creating some sample inputs and then calling the forward method and recording / tracing by a function called torch.jit.trace. The scripting method is useful when there is some control flow (data dependent execution) in the model. We show the tracing method below for our Speech Commands quantized model.</p>\n<h4>LOAD MODEL WEIGHTS, QUANTIZE WEIGHTS TO 8-BIT</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">PATH <span class=\"token operator\">=</span> <span class=\"token string\">\"./models/speech_commands_model.pt\"</span>\nnnModel <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>SpeechCommandsModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>       <span class=\"token comment\"># Instantiate our model and move model to GPU if available</span>\nnnModel<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>PATH<span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nquantized_model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>quantization<span class=\"token punctuation\">.</span>quantize_dynamic<span class=\"token punctuation\">(</span>\n    nnModel<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">,</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>qint8<span class=\"token punctuation\">)</span>\nquantized_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nnnModel<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h4>MODEL TRACING WITH INPUTS</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">testFiles <span class=\"token operator\">=</span> utils<span class=\"token punctuation\">.</span>get_filenames<span class=\"token punctuation\">(</span><span class=\"token string\">'files'</span><span class=\"token punctuation\">,</span>searchstr<span class=\"token operator\">=</span><span class=\"token string\">'SCRIC20*'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> scd<span class=\"token punctuation\">.</span>get_file_features<span class=\"token punctuation\">(</span>testFiles<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\ntraced_model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>jit<span class=\"token punctuation\">.</span>trace<span class=\"token punctuation\">(</span>quantized_model<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>traced_model<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SpeechCommandsModel(\n  original_name=SpeechCommandsModel\n  (conv1): Conv2d(original_name=Conv2d)\n  (bn1): BatchNorm2d(original_name=BatchNorm2d)\n  (conv2): Conv2d(original_name=Conv2d)\n  (bn2): BatchNorm2d(original_name=BatchNorm2d)\n  (fc1): Linear(\n    original_name=Linear\n    (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n  )\n  (bn3): BatchNorm1d(original_name=BatchNorm1d)\n  (fc2): Linear(\n    original_name=Linear\n    (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n  )\n)</code></pre></div>\n<h4>TORCHSCRIPT SCRIPTMODULE INTERMEDIATE REPRESENTATION</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>traced_model<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def forward(self,\n    input: Tensor) -&gt; Tensor:\n  _0 = self.fc2\n  _1 = self.bn3\n  _2 = self.fc1\n  _3 = self.bn2\n  _4 = self.conv2\n  _5 = (self.bn1).forward((self.conv1).forward(input, ), )\n  input0 = torch.max_pool2d(_5, [2], annotate(List[int], []), [0, 0], [1, 1], False)\n  input1 = torch.relu(input0)\n  _6 = (_3).forward((_4).forward(input1, ), )\n  input2 = torch.max_pool2d(_6, [2], annotate(List[int], []), [0, 0], [1, 1], False)\n  x = torch.relu(input2)\n  x0 = torch.view(x, [-1, 1536])\n  x1 = torch.relu((_1).forward((_2).forward(x0, ), ))\n  _7 = torch.log_softmax((_0).forward(x1, ), 1, None)\n  return _7</code></pre></div>\n<h4>VERIFY THAT OUTPUTS ARE MATCHING</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>traced_model<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>             <span class=\"token comment\"># TORCHSCRIPT version of QUANTIZED MODEL</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>quantized_model<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>          <span class=\"token comment\"># QUANTIZED MODEL</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>nnModel<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>                  <span class=\"token comment\"># ORIGINAL MODEL</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">tensor([[-3.4839, -4.6787, -1.6807, -6.9479, -0.3579, -4.0282, -8.1275, -5.0048,\n         -6.2447, -5.5977, -3.1421]])\ntensor([[-3.4839, -4.6787, -1.6807, -6.9479, -0.3579, -4.0282, -8.1275, -5.0048,\n         -6.2447, -5.5977, -3.1421]])\ntensor([[-3.4179, -4.6061, -1.6919, -6.9600, -0.3590, -4.0849, -8.1481, -4.9647,\n         -6.2618, -5.5800, -3.1247]], grad_fn=&lt;LogSoftmaxBackward&gt;)</code></pre></div>\n<h3>What is special about this TorchScript code?</h3>\n<p>According to the official tutorial, there are several advantages to having a intermediate representation of the model graph</p>\n<ol>\n<li>TorchScript code can be invoked in its own interpreter and many requests can be\nprocessed on the same instance simultaneously due to absence of a global instance lock</li>\n<li>This format allows to save the whole model to disk and load it\ninto another environment</li>\n<li>TorchScript gives a representation in which we can do compiler\noptimizations</li>\n<li>TorchScript allows to interface with many backend/device runtimes</li>\n</ol>\n<p>Let’s take their word for it and keep these in mind for now and remind ourselves later when we see the usecase in action.</p>\n<h2>Serialize the the Script Module to a file</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">traced_model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">'models/traced_qsc.zip'</span><span class=\"token punctuation\">)</span>\nloaded <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>jit<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">'models/traced_qsc.zip'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>loaded<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>loaded<span class=\"token punctuation\">.</span>code<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">RecursiveScriptModule(\n  original_name=SpeechCommandsModel\n  (conv1): RecursiveScriptModule(original_name=Conv2d)\n  (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n  (conv2): RecursiveScriptModule(original_name=Conv2d)\n  (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n  (fc1): RecursiveScriptModule(\n    original_name=Linear\n    (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n  )\n  (bn3): RecursiveScriptModule(original_name=BatchNorm1d)\n  (fc2): RecursiveScriptModule(\n    original_name=Linear\n    (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n  )\n)\ndef forward(self,\n    input: Tensor) -&gt; Tensor:\n  _0 = self.fc2\n  _1 = self.bn3\n  _2 = self.fc1\n  _3 = self.bn2\n  _4 = self.conv2\n  _5 = (self.bn1).forward((self.conv1).forward(input, ), )\n  input0 = torch.max_pool2d(_5, [2], annotate(List[int], []), [0, 0], [1, 1], False)\n  input1 = torch.relu(input0)\n  _6 = (_3).forward((_4).forward(input1, ), )\n  input2 = torch.max_pool2d(_6, [2], annotate(List[int], []), [0, 0], [1, 1], False)\n  x = torch.relu(input2)\n  x0 = torch.view(x, [-1, 1536])\n  x1 = torch.relu((_1).forward((_2).forward(x0, ), ))\n  _7 = torch.log_softmax((_0).forward(x1, ), 1, None)\n  return _7</code></pre></div>\n<h2>Load the Script Module in C++</h2>\n<p>The PyTorch C++ API, also known as LibTorch, is used to load the serialized PyTorch model in C++. The LibTorch distribution consists of shared libraries, headers and build config files. CMake is the recommended build configuration tool.</p>\n<p>We have a few (boring install) steps to do now</p>\n<ol>\n<li>Download and install <a href=\"https://pytorch.org/cppdocs/installing.html\">LibTorch</a>. Just a measly 2 GB unzipped.</li>\n<li>Install <a href=\"https://cmake.org/download/\">CMake</a> if you don’t have it already</li>\n</ol>\n<p>Next let us try to compile a fairly simple C++ program which loads the serialized ScriptModule (.zip file that was created earlier) and then passes a random input tensor to the model for prediction.</p>\n<div class=\"gatsby-highlight\" data-language=\"cpp\"><pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;torch/script.h></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream></span></span>\n<span class=\"token macro property\">#<span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;memory></span></span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> argc<span class=\"token punctuation\">,</span> <span class=\"token keyword\">const</span> <span class=\"token keyword\">char</span><span class=\"token operator\">*</span> argv<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>argc <span class=\"token operator\">!=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    std<span class=\"token operator\">::</span>cerr <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"usage: example-app &lt;path-to-exported-script-module>\\n\"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n\n  torch<span class=\"token operator\">::</span>jit<span class=\"token operator\">::</span>script<span class=\"token operator\">::</span>Module module<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// Deserialize the ScriptModule from a file using torch::jit::load().</span>\n    module <span class=\"token operator\">=</span> torch<span class=\"token operator\">::</span>jit<span class=\"token operator\">::</span><span class=\"token function\">load</span><span class=\"token punctuation\">(</span>argv<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> c10<span class=\"token operator\">::</span>Error<span class=\"token operator\">&amp;</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    std<span class=\"token operator\">::</span>cerr <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"error loading the model\\n\"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  std<span class=\"token operator\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"Model \"</span><span class=\"token operator\">&lt;&lt;</span> argv<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">&lt;&lt;</span><span class=\"token string\">\" loaded fine\\n\"</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// Create a vector of inputs.</span>\n  std<span class=\"token operator\">::</span>vector<span class=\"token operator\">&lt;</span>torch<span class=\"token operator\">::</span>jit<span class=\"token operator\">::</span>IValue<span class=\"token operator\">></span> inputs<span class=\"token punctuation\">;</span>\n  inputs<span class=\"token punctuation\">.</span><span class=\"token function\">push_back</span><span class=\"token punctuation\">(</span>torch<span class=\"token operator\">::</span><span class=\"token function\">randn</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">101</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// Execute the model and turn its output into a tensor.</span>\n  at<span class=\"token operator\">::</span>Tensor output <span class=\"token operator\">=</span> module<span class=\"token punctuation\">.</span><span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toTensor</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  std<span class=\"token operator\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> output <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">int</span> y_hat <span class=\"token operator\">=</span> output<span class=\"token punctuation\">.</span><span class=\"token function\">argmax</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">item</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">toInt</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  std<span class=\"token operator\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"Predicted class: \"</span> <span class=\"token operator\">&lt;&lt;</span> y_hat <span class=\"token operator\">&lt;&lt;</span><span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3>Build Procedure</h3>\n<p>We have the following directory structure</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">projects\n  example-app\n    example-app.cpp\n    CMakeList.txt</code></pre></div>\n<p>The CMakeList.txt consists of the following commands</p>\n<div class=\"gatsby-highlight\" data-language=\"cmake\"><pre class=\"language-cmake\"><code class=\"language-cmake\"><span class=\"token keyword\">cmake_minimum_required</span><span class=\"token punctuation\">(</span><span class=\"token property\">VERSION</span> <span class=\"token number\">3.0</span> FATAL_ERROR<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">project</span><span class=\"token punctuation\">(</span>example-app<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">find_package</span><span class=\"token punctuation\">(</span>Torch REQUIRED<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token variable\">CMAKE_CXX_FLAGS</span> <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token punctuation\">${</span><span class=\"token variable\">CMAKE_CXX_FLAGS</span><span class=\"token punctuation\">}</span></span> <span class=\"token interpolation\"><span class=\"token punctuation\">${</span><span class=\"token variable\">TORCH_CXX_FLAGS</span><span class=\"token punctuation\">}</span></span>\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">add_executable</span><span class=\"token punctuation\">(</span>example-app example-app.cpp<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">target_link_libraries</span><span class=\"token punctuation\">(</span>example-app <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token punctuation\">${</span><span class=\"token variable\">TORCH_LIBRARIES</span><span class=\"token punctuation\">}</span></span>\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">set_property</span><span class=\"token punctuation\">(</span>TARGET example-app PROPERTY <span class=\"token property\">CXX_STANDARD</span> <span class=\"token number\">14</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>We then issue the following terminal commands (change for your setup as needed!):</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">cd projects/example-app\nmkdir build\ncd build\ncmake -DCMAKE_PREFIX_PATH=/home/ragh/Downloads/libtorch ..\ncmake --build . --config Release\n./example-app ../../../models/traced_qsc.zip\n./example-app ../../../models/traced_qsc.zip\nModel ../../../models/traced_qsc.zip loaded fine\nColumns 1 to 10-7.8962 -8.8210 -4.3701 -7.6351 -4.3408 -6.9469 -5.3084 -4.0581 -4.6869 -7.8740\n\nColumns 11 to 11-0.0613\n[ CPUFloatType{1,11} ]\nPredicted class: 10</code></pre></div>\n<h2>Conclusion</h2>\n<p>Using tracing, we created a serialized TorchScript ScriptModule of our speech commands model. We then loaded this model using the C++ API and performed a model prediction in C++. The output we got to a random input was classified as Unknown/Background class, which is expected.</p>\n<p>I should say that I did attempt to try this same example on MacOS and it did not work out (linker error). However, I gave it another shot on the Ubuntu box and it worked fine.</p>\n<p>One challenge that we still need to address is how to pipe inputs to the C++ environment. Torchaudio is absent in the C++ realm, so feature processing will be an issue or a lot of work. This motivates us to look into things like CoreML (in Apple ecosystem) and the ONNX runtimes in future posts.</p>\n<p>While I do believe PyTorch is the way to go as far as model development goes, it may not be a bad idea to leverage tensorflow lite and things like that in the TF ecosystem which people have shown to run on resource-constrained MCUs.</p>\n<p>While this may not the most exciting/interesting topic to post on, it is very critical if you want an efficient path to deployment.</p>","excerpt":"In this post we will go through the steps of running a pre-trained PyTorch model in C++ on MacOS (or other platform where you can compile C/C++). The steps are…","frontmatter":{"title":"How To Run a pre-trained PyTorch model in C++","date":"2020-09-02T00:00:00.000Z","subject":["ml","howto","pytorch","deploy","C++","TorchScript"],"author":"RSP","featimg":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAABNUlEQVQ4y6WTW0/CQBCFd/bSCwotRsqlgIEWqGgN4IOSoIb4auKD//+3HIetRBMUKTycdrPb/fbMnK0QQuB3Ef5e2yt+kPye0O4psAKo2lOYyRrkB9DDJVQrA1UjyKADFef2XQ7YXzDoESZ7tWMzfoEze4dOV3DyN+irewipypSsbJmy3uWNGsK/YLc1kHcOOqt/wagE8EcItHGsdz8kKcoCCylDiHMPUericuCglbloTlz0Zh7CjkY0ctAYshLnMOBGYazRX/iIbz00x8XmZFlBZ+rawwYPvp0/GPifpCpR8l4QFT3e9vokYFghrLnMp9SBb05wuHXyzGEEPkGxy24oGWxQ8wg3bY077nlp4LSlMe9p5Jz0NY8/5nwTqhKrxFjnR/VwFCmkjeKP0XL30KNT3hfMJyQWPRIuOivFAAAAAElFTkSuQmCC","aspectRatio":1.2987012987012987,"src":"/static/19ddca2efd2a5f194057b4ce4de6f60f/497c6/output.png","srcSet":"/static/19ddca2efd2a5f194057b4ce4de6f60f/65e33/output.png 100w,\n/static/19ddca2efd2a5f194057b4ce4de6f60f/69585/output.png 200w,\n/static/19ddca2efd2a5f194057b4ce4de6f60f/497c6/output.png 400w,\n/static/19ddca2efd2a5f194057b4ce4de6f60f/2a4de/output.png 600w,\n/static/19ddca2efd2a5f194057b4ce4de6f60f/ee604/output.png 800w,\n/static/19ddca2efd2a5f194057b4ce4de6f60f/836fd/output.png 892w","sizes":"(max-width: 400px) 100vw, 400px"}}}},"fields":{"slug":"/howto-pytorch-c++/output/","readingTime":{"text":"7 min read"}}},"site":{"siteMetadata":{"title":"JumpML"}}},"pageContext":{"slug":"/howto-pytorch-c++/output/"}}}