{"componentChunkName":"component---src-templates-blog-post-js","path":"/tutorial-pytorch-speechcommands-quantize/output/","result":{"data":{"markdownRemark":{"html":"<p>In this post, we want to see if the speech commands recognition model we trained in the <a href=\"https://jumpml.com/tutorial-pytorch-speechcommands/output/\">previous post</a> actually works on real recorded data.</p>\n<p>In addition we will learn how to quantize weights in PyTorch. This will help make the model smaller and potentially faster for prediction. Performance may or may not get worse.</p>\n<p>This notebook is available on github at this <a href=\"https://github.com/jumpml/pytorch-tutorials/blob/master/SpeechCommands_CNN_quantize.ipynb\">link</a>.</p>\n<h2>Model Loading</h2>\n<p>In a previous post, we trained a simple CNN model to recognize speech commands. We will load the same exact model with the same input size, kernel sizes, layers, etc. There are two steps in model loading</p>\n<ol>\n<li>Model instantiation: this is the skeleton with space for the parameters</li>\n<li>Parameter loading from a previously saved .pt file</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">PATH <span class=\"token operator\">=</span> <span class=\"token string\">\"./models/speech_commands_model.pt\"</span>\nnnModel <span class=\"token operator\">=</span> models<span class=\"token punctuation\">.</span>SpeechCommandsModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>       <span class=\"token comment\"># Instantiate our model and move model to GPU if available</span>\nnnModel<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>PATH<span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nnnModel<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SpeechCommandsModel(\n  (conv1): Conv2d(1, 32, kernel_size=(8, 20), stride=(1, 1))\n  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(32, 8, kernel_size=(4, 10), stride=(1, 1))\n  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc1): Linear(in_features=1536, out_features=128, bias=True)\n  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (fc2): Linear(in_features=128, out_features=11, bias=True)\n)</code></pre></div>\n<h2>Model Quantization</h2>\n<p>As of PyTorch 1.6.0, there are three ways to quantize a model</p>\n<ol>\n<li>Dynamic Quantization: quantized weights applied post-training</li>\n<li>Static Quantization: fuses layers like BatchNorm and Relu, uses data for calibration applied post-training</li>\n<li>Quantization-aware training: static quantization during training</li>\n</ol>\n<p>We will try out the easiest one, dynamic quantization, which I am just going to call weight quantization. Basically we need to tell the quantizer which layers we want to quantize, for e.g. nn.Linear usually has a lot of parameters and is a prime candidate for weight quantization and what the target data type is. Since parameters are float32, the two options available are float16 or qint8. We will convert Conv2d and Linear layers to 8-bit parameters.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">quantized_model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>quantization<span class=\"token punctuation\">.</span>quantize_dynamic<span class=\"token punctuation\">(</span>\n    nnModel<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">,</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>qint8<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">utils<span class=\"token punctuation\">.</span>print_size_of_model<span class=\"token punctuation\">(</span>nnModel<span class=\"token punctuation\">)</span>\nutils<span class=\"token punctuation\">.</span>print_size_of_model<span class=\"token punctuation\">(</span>quantized_model<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Size (MB): 0.864021\nSize (MB): 0.271357</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">lossFn <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>nll_loss  <span class=\"token comment\">#When we combine nll_loss and log_softmax we get a cross entropy loss</span>\nevalSC <span class=\"token operator\">=</span> <span class=\"token builtin\">eval</span><span class=\"token punctuation\">.</span>evalModel<span class=\"token punctuation\">(</span>nnModel<span class=\"token punctuation\">,</span> lossFn<span class=\"token punctuation\">,</span> device<span class=\"token punctuation\">)</span>\nevalSCq <span class=\"token operator\">=</span> <span class=\"token builtin\">eval</span><span class=\"token punctuation\">.</span>evalModel<span class=\"token punctuation\">(</span>quantized_model<span class=\"token punctuation\">,</span> lossFn<span class=\"token punctuation\">,</span> device<span class=\"token punctuation\">)</span>\nevalSC<span class=\"token punctuation\">.</span>evalClass<span class=\"token punctuation\">(</span>sc_data<span class=\"token punctuation\">.</span>test_loader<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Avg. loss: 0.0007, Accuracy: 94.42631530761719 %  Elapsed Time=126.23865580558777</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">evalSCq<span class=\"token punctuation\">.</span>evalClass<span class=\"token punctuation\">(</span>sc_data<span class=\"token punctuation\">.</span>test_loader<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Avg. loss: 0.0007, Accuracy: 94.39006805419922 %  Elapsed Time=36.33142900466919</code></pre></div>\n<h2>To Quantize or Not to Quantize?</h2>\n<p>Here is the deal</p>\n<ol>\n<li>Size went down from 0.86 MB to 0.27 MB</li>\n<li>Accuracy is slightly worse, but pretty much the same: 94.42% to 94.39%</li>\n<li>Processing time of the test set evaluation went from 2 minutes to half a minute!</li>\n</ol>\n<p>Usually there are no free lunches, but what we have here is a free lunch, a proverbial no-brainer.</p>\n<h2>Recording real-world data</h2>\n<p>I used Audacity, a free audio editing tool, to record me saying twenty commands one after the other. After that, I wrote up an Energy-based Voice Activity Detector (VAD) which basically finds the words in the long recording:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/aa75e30e0b52c3c0000a8ed42afb0e9f/5819f/VAD.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 84.45945945945947%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAxNAAAMTQHSzq1OAAAC+ElEQVQ4y61U2Y7URhT1Z+QfIsFkIvGJiEXKA/ApUeYJCaQoybSUAXqb6d3d3vd9KbuqTm65DQxJJHigpKO7n3tt17U2m81+bNt2zhhbEhaj/AIUX/6f/x5U3aZpmrdaHMcX+MoR+LYjpAy19WZ7KXjfo2uk7BqOngnZlkL2rQBBdrWoquqsD2jI14yyHvWWq7bEY2lOEF2InnGUPpA7EnWM1rlFlXhAk0BkFqo0gKgiSIqhClBHFvqSdKqRuUv+RKChHFbZmuMFF7xjXBQ+FTuyKyJExzlC3wHqBIl7QhJ5yGN/sFGFyAMTXXkml4VqnBJheCbUj6dLxlruWCfkviGLJIC9ncK0TMShB8c8wPdd7E4G2T6SwEFITZo8Qh46iD0DRRoK1GrC2tbSvHzQE+F2v0fsHmUa+fB2H3AyDBiWBY8IXdfB9WI7SMsycNT38HwPWWBjf9hRQ0+gosfviDDynMu0KPnV9Rz68SBnWx3T6XtMllv8Md/iZrHCzeqA3ya3uF7u8e5uhzc3C/w6ucPvH1aYzFf4c7kXbeqBs4HQ+imvW/566WDnZXJ6ijAzYvx9CHC983FrJWRHuJqaeH8MsTBj/EX+t3cuFhSb7ALc6KGgrwDOua3FYfCw6zlfeQXstJF+3sJJG+z8EltCUDB45JscIrhZO+hO1iCuGLK6w4bqKH+4qlJKW1vf3f7MiFAPK0RlK1WindYw4wph0cLPmwH7oBwIEopHJUPXC6SkjzlnQiFstSkPhBA8pWRBV51RoprQoynUialYoWI9ximQNx06ekSlcyHRKENtiiJcr9eXinDcHqkSMiqo2dmlZNn2Q7GCOoq85+I/2zkQmqZ58ZFQjhWqoZr040T3pxt39lODEZ8Jbdt+SEpLdk+BjqI9de+JtCMK5euJsFNSxUf8W2eKkL6yoW02m0f4fqfUXNf9IU3Tp/RHeVbX9RPLsl6Q/Zz+bU/odbzMsuy58huG8aooimeU91TpSipb6Sqe5/kvuq4//gchof0wUquvTgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"VAD\"\n        title=\"VAD\"\n        src=\"/static/aa75e30e0b52c3c0000a8ed42afb0e9f/fcda8/VAD.png\"\n        srcset=\"/static/aa75e30e0b52c3c0000a8ed42afb0e9f/12f09/VAD.png 148w,\n/static/aa75e30e0b52c3c0000a8ed42afb0e9f/e4a3f/VAD.png 295w,\n/static/aa75e30e0b52c3c0000a8ed42afb0e9f/fcda8/VAD.png 590w,\n/static/aa75e30e0b52c3c0000a8ed42afb0e9f/efc66/VAD.png 885w,\n/static/aa75e30e0b52c3c0000a8ed42afb0e9f/5819f/VAD.png 1042w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>At the end, we have a set of twenty files corresponding to the twenty commands I read. The filename contains the true command label.</p>\n<p>The next steps are to setup a feature preprocessing pipeline so we can feed the features to the model. After some copy and paste of the dataset code, we create a function:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> scd<span class=\"token punctuation\">.</span>get_file_features<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>which takes a filename and returns the features X (101 frames of 64 log Mel features) and label y. This function also allows to pad silence to the right of the command or pad on both left and right of the command.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> testFiles<span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> scd<span class=\"token punctuation\">.</span>get_file_features<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span> conf<span class=\"token punctuation\">)</span><span class=\"token operator\">=</span>evalSCq<span class=\"token punctuation\">.</span>predictClass<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> pred <span class=\"token operator\">==</span> y<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'\\033[1;30;47m Ground Truth = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>y<span class=\"token punctuation\">}</span></span><span class=\"token string\"> \\tPrediction = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred<span class=\"token punctuation\">}</span></span><span class=\"token string\">   \\tConfidence=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conf <span class=\"token operator\">*</span> <span class=\"token number\">100</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'\\033[1;30;41m Ground Truth = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>y<span class=\"token punctuation\">}</span></span><span class=\"token string\"> \\tPrediction = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred<span class=\"token punctuation\">}</span></span><span class=\"token string\">   \\tConfidence=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conf <span class=\"token operator\">*</span> <span class=\"token number\">100</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1;30;47m Ground Truth = 4 \tPrediction = 4   \tConfidence=69.92%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=91.55%\n\u001b[1;30;47m Ground Truth = 8 \tPrediction = 8   \tConfidence=99.97%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=77.36%\n\u001b[1;30;47m Ground Truth = 3 \tPrediction = 3   \tConfidence=56.72%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=98.91%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=98.08%\n\u001b[1;30;47m Ground Truth = 1 \tPrediction = 1   \tConfidence=95.63%\n\u001b[1;30;47m Ground Truth = 7 \tPrediction = 7   \tConfidence=94.43%\n\u001b[1;30;47m Ground Truth = 9 \tPrediction = 9   \tConfidence=99.46%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=84.82%\n\u001b[1;30;47m Ground Truth = 0 \tPrediction = 0   \tConfidence=99.06%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=75.87%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=95.41%\n\u001b[1;30;47m Ground Truth = 5 \tPrediction = 5   \tConfidence=89.63%\n\u001b[1;30;47m Ground Truth = 6 \tPrediction = 6   \tConfidence=84.86%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=98.45%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=96.55%\n\u001b[1;30;41m Ground Truth = 2 \tPrediction = 10   \tConfidence=44.08%   ===&gt; OH NOOOOOOOOOOOOOO\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=69.66%</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># VISUALIZE SOME EXAMPLES</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">visualize_file_prediction</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> evalSC<span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> scd<span class=\"token punctuation\">.</span>get_file_features<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span>padLR<span class=\"token operator\">=</span>padLR<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span> conf<span class=\"token punctuation\">)</span><span class=\"token operator\">=</span>evalSC<span class=\"token punctuation\">.</span>predictClass<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n    fig<span class=\"token operator\">=</span>plt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dpi<span class=\"token operator\">=</span><span class=\"token number\">80</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>tight_layout<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'jet'</span><span class=\"token punctuation\">,</span> origin<span class=\"token operator\">=</span><span class=\"token string\">'lower'</span><span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Ground Truth: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>scd<span class=\"token punctuation\">.</span>KNOWN_COMMANDS<span class=\"token punctuation\">[</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">    Prediction:</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>scd<span class=\"token punctuation\">.</span>KNOWN_COMMANDS<span class=\"token punctuation\">[</span>pred<span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n\nvisualize_file_prediction<span class=\"token punctuation\">(</span>testFiles<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> evalSCq<span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 542px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f0ad18f71da0683421c5769d8394aef6/c0388/output_15_0.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAxNAAAMTQHSzq1OAAAC7UlEQVQ4y42TW0hUURSG/+N1UIpMnTEsb6ghlFNimWljWYFloqYphULQSxFeMEcLHS9lGVlK4VNEZTlPEllhmqLQQ6lBzqRkdkE0y7ygOeN19JxZLVNJhLKHj7XX3nv9/Oec/wBRWgegVgGVVo6Uu3L4xvkh5IgSwTFKbIlSIiLZB5GJfnAO2AH4+AO+2wDvQGCzEgjfCCQ6A0flC0RYA7GjzbLS8Tnh5JwBUTSOePMUomanoZqdRPTsFI6JU4ijSXg1TgMZ0xA0XHNmGK6aCWYcyGNymdQQrNV8fefeMUAInCXBtodg10tW4RNkkUkEp3GCzWeG9y20xCLMRaZgBYVMPpMeBuvyIZ2nsYesT4+JQJMZKDNb7msxyypEM+w7ub/N3GCKGA2Tz+QtR1rYmz9LV6H6xV6docGJ1KaLonsLuznYR2si9OTwzEBwZOd4RBCquZYwuYtOljMvOl819FuwpiNIN9jlSvmkFj36PhIO8OMqPpAQyIJWT/nSHeYBc3lxaBVB9WC27j4lkdtwt4igQRLAIu56fqciX2hlKhdcovj/BKu6wvQ9I5so3vhQtLlpJPh8J2H3KNlWm0hINfMH6SVY9jPzotmLH+EfgkMlsjZKAg28dxTVVEjrXw8T3yH752OEDHbpJhFcudrV8UDW6oK6FIW+dz+op8JBbDUpKfablizvmUh2ld0mslDQDCGAI6R4yQPqZRH5i+CXBNnbToBGSm3m6mmPtL2tWQp90ygdFqsk4dachOAZCYckCV71HI8sCUKBtBCV5SzFJk2Fzisu7aQCUTmoTDpL0BJtrW6ndZXs8AKRkMbuihn/JnZwniN0adHlEiuCfV2f/Kqpc6eptl31M6Sh1mil7jZaJ3wyCKf6DRaFM0bL9H4DYn8YIH9sYIdGHuSqWcL4Z53D65QQILPIFfREgdE6OWxq3IEYDw4w/+jXmHPewBlX4Divo11gscuHzzcASdxH8n4Q9ycUQDL3oZ6AwvEXoePaWLz7wpcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/f0ad18f71da0683421c5769d8394aef6/c0388/output_15_0.png\"\n        srcset=\"/static/f0ad18f71da0683421c5769d8394aef6/12f09/output_15_0.png 148w,\n/static/f0ad18f71da0683421c5769d8394aef6/e4a3f/output_15_0.png 295w,\n/static/f0ad18f71da0683421c5769d8394aef6/c0388/output_15_0.png 542w\"\n        sizes=\"(max-width: 542px) 100vw, 542px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>What if the speech was more centered? Would the prediction change? Let see.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">visualize_file_prediction<span class=\"token punctuation\">(</span>testFiles<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> evalSCq<span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 542px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f21554f26726b732088ff368cbb2a865/c0388/output_17_0.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAxNAAAMTQHSzq1OAAADMklEQVQ4y32TfUxVdRjHv+cFxpXZItq9EjZ86camK7GkUBw2nSKkFiBzrZxBrpgvwAoE9L5wzZC1pX8gG3O61VqNTMdfrTWxYa1aUUq6Moa3MQKvgi/3XAYXuJzz7Tl4nW5Jf3z2PL9zfs/3fH+/5zkAilKAEheUrU6g0KW++OHjSK52Q3tlOXIKl2FBfhbydriVV8uehntDNp4vyEJB8VJsa3IBdk2xUBKPGxMA1P0E+GJQ/Abw3iie6RpNPDw9pu8LR1HAcRQLJdPjWBMbw4aJKEolL2UUuddHpU7wxqNHqMwVwf2/Ax8QaoDAPiLnOy66MsjEyjF5NkI8epVqRpi6xyKWm4T2N5HUL7FL9vuFRiEQz6vXiGD9ReB92RCYBmosbD5vpd8JWamfXrMw94oFtFpI7rAc7WOWkjMi6y+Eo0Kz4BX8phDPq/NEsEEED1HTvSJ4kEW1exjudLJ9aAuX/dNNx/4QtYw/6fpqgFg/KS6+IZQzEtsEL++K+eP5A4Kq7psR3FxZzZvBNLaPbOJKq5OaZ0qO3Uc1+xaR+rMUnRA+Fz76f0FF84ugh0veaGE7S1nA00S97UjuKqmTWD1BOIKyPiV0CC209z9EsL7nvsMAN1bVciicxubwbj52LkRlnTQm/ToTWyeot0lj0oelcJBI+GVWhxdsQV3ziOBhvlu+iawAYx+r/EScZoYvEwdIx5cR6sfF5VIS8+UaUvrinfU93KGm2k1p4q7irRzeAv5V62Dv4GI2TtVw7qnbnNNmUNkpQnkx4jmJ7tBsgg2/2WOjq56YODTrX843B5wwg+sSzN7xxeaboVbzia/7zfJYi5nSdcNEvmXipQkTef0yLr4498amakbwku1M03y0j1z+1g5yG8gy8MfwC3zy1wE+cmyUS779g9IDqlVyj01y7NJQfKj/M9h1P8hXJlXNe0e+Eln59sHI2aG1xvc9zxrvdB+JJDcHDe21oKGXBQ2lLhrRGm4aKAsZyOw27P2CRJ9wQPK99q+3Kh143QV1u1NBbgYWVi5A9LzTwc+cyD35lDiQ9xXy4wfmSYFbYhqwW9br5fkK90wttst69ULAlfovBU7ZQm15SQQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"png\"\n        title=\"png\"\n        src=\"/static/f21554f26726b732088ff368cbb2a865/c0388/output_17_0.png\"\n        srcset=\"/static/f21554f26726b732088ff368cbb2a865/12f09/output_17_0.png 148w,\n/static/f21554f26726b732088ff368cbb2a865/e4a3f/output_17_0.png 295w,\n/static/f21554f26726b732088ff368cbb2a865/c0388/output_17_0.png 542w\"\n        sizes=\"(max-width: 542px) 100vw, 542px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> <span class=\"token builtin\">file</span> <span class=\"token keyword\">in</span> testFiles<span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> scd<span class=\"token punctuation\">.</span>get_file_features<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> padLR<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">,</span> conf<span class=\"token punctuation\">)</span><span class=\"token operator\">=</span>evalSCq<span class=\"token punctuation\">.</span>predictClass<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> pred <span class=\"token operator\">==</span> y<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'\\033[1;30;47m Ground Truth = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>y<span class=\"token punctuation\">}</span></span><span class=\"token string\"> \\tPrediction = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred<span class=\"token punctuation\">}</span></span><span class=\"token string\">   \\tConfidence=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conf <span class=\"token operator\">*</span> <span class=\"token number\">100</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'\\033[1;30;41m Ground Truth = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>y<span class=\"token punctuation\">}</span></span><span class=\"token string\"> \\tPrediction = </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred<span class=\"token punctuation\">}</span></span><span class=\"token string\">   \\tConfidence=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conf <span class=\"token operator\">*</span> <span class=\"token number\">100</span> <span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">\u001b[1;30;47m Ground Truth = 4 \tPrediction = 4   \tConfidence=99.95%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.91%\n\u001b[1;30;47m Ground Truth = 8 \tPrediction = 8   \tConfidence=100.00%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=83.48%\n\u001b[1;30;47m Ground Truth = 3 \tPrediction = 3   \tConfidence=99.73%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.49%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.83%\n\u001b[1;30;47m Ground Truth = 1 \tPrediction = 1   \tConfidence=98.30%\n\u001b[1;30;47m Ground Truth = 7 \tPrediction = 7   \tConfidence=99.97%\n\u001b[1;30;47m Ground Truth = 9 \tPrediction = 9   \tConfidence=100.00%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.73%\n\u001b[1;30;47m Ground Truth = 0 \tPrediction = 0   \tConfidence=100.00%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.26%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.59%\n\u001b[1;30;47m Ground Truth = 5 \tPrediction = 5   \tConfidence=99.99%\n\u001b[1;30;47m Ground Truth = 6 \tPrediction = 6   \tConfidence=99.69%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=97.21%\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=99.59%\n\u001b[1;30;47m Ground Truth = 2 \tPrediction = 2   \tConfidence=98.81%   ==&gt; ALRIGHTY THEN\n\u001b[1;30;47m Ground Truth = 10 \tPrediction = 10   \tConfidence=56.80%</code></pre></div>\n<h2>Conclusion</h2>\n<p>Quantizing to 8-bit parameters is a great thing to do for our pre-trained speech commands model.</p>\n<p>We also noticed the fragility of the model to where in the spectrogram the word is. This may not be an issue in practice, as the model may be run multiple times a second on overlapping data. Yet, it shows that there is more work to do on getting a more invariant representation. We see the need for more tools to perform sensitivity analysis to noise and perturbations like time shift. And the need to understand why the model is getting confused by using model interpretability libraries like <a href=\"https://captum.ai\">Captum</a>. These will be topics for a future post.</p>","excerpt":"In this post, we want to see if the speech commands recognition model we trained in the previous post actually works on real recorded data. In addition we will…","frontmatter":{"title":"Predictions on real data and model quantization (Tutorial)","date":"2020-08-28T00:00:00.000Z","subject":["ml","tutorial","pytorch","audio","speech","kws","voice","cnn","quantization"],"author":"RSP","featimg":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAxNAAAMTQHSzq1OAAADCElEQVQ4y12TW0hUURSG/3NmNLNGRRLUSjQVCkrKyqJIigjshtVI94KSIBGi8pIjOU5m2mUmR7sKFUX1Uj11e+ihHgq6YUyoZZeXEoouRDI354xz/taZKSsP/Ox19j7rO/9ea28g+qxLAzZkQtmYAazJxKJL6YjbU4CsTYWYUzYTU9ZPx3pbPuZvmYECaxEWry3E9oZcpNelA9bfeRvGSzxWYGkpQF0XYI9AafQBNQEseu1P7PANquWBEEo4CCtDWBYJYoE2iJXhENZEQljBIFIu+4HaANDoFRGo3ivAyaOB+l7gEKE6ZLKe5q09nPDuMzFPk/d3RNxrmpd7qVaTGP2VMHcTJo+suUUNIocOtMpYu0+AmUmArQc4aACHxK0+xvZcL/S+0FOb+3VYHsnHp/S4lV16QqcmsUd0UtQmahTZjTEcNYSaWgHmjPkDNKkNEWOh5XQpeRd0aTuZ/6WPWD7AJGsvLed8RMJbSbwuusaoiRhwKAasNYATLbLNbmNRNRnAZla0V7L7x1RWBxzMePieKPxEpL4hJsp2cUV0UXTWgDHm8j9g9rBD1SSNQRNXuFt5g6XM/ilu5vqp4A4xVYAlUsNRRu1uie7S+LnUcCQwN3Hklpvdqxh8EE9XfwXzHr+iss5PtdRPi2eAqBKo+p1I/CaATpFNgI5/gVljh4GKAWzhhd1zya2g72E827iDOb3i7hCpnJGul0SI/CEiV+L4SzSaOAKY99chYsDOsjl8mQP2OVL4NjCJ1v7LzLjzgXm35bjs1olZ0pyiMJFk1HPfSOB4aYrNAxwQh/sHBaid3zxbCydD87WatKtcrSXf/KYtfHpPm//pvoZKalgS1lCua0g7r4lDkSMY63hNjQCnJUiXPwIuqWGLTLaxyVlOnrYwdH0c7V4nlQtk2qkBmo9K/Zyk2s5YLVON43NAdDiaJ27txtWTm7KrXly2K6Y6p9juWHDkiPskNztbvNuOJ7u6TijFz1yY9tSlLOtxK2X9HUqxx4XsJy6ozSeAqjbJPSZ5Z4Dypb8AtrW1wMmjhlQAAAAASUVORK5CYII=","aspectRatio":1.492537313432836,"src":"/static/f21554f26726b732088ff368cbb2a865/497c6/output_17_0.png","srcSet":"/static/f21554f26726b732088ff368cbb2a865/65e33/output_17_0.png 100w,\n/static/f21554f26726b732088ff368cbb2a865/69585/output_17_0.png 200w,\n/static/f21554f26726b732088ff368cbb2a865/497c6/output_17_0.png 400w,\n/static/f21554f26726b732088ff368cbb2a865/00f6e/output_17_0.png 542w","sizes":"(max-width: 400px) 100vw, 400px"}}}},"fields":{"slug":"/tutorial-pytorch-speechcommands-quantize/output/","readingTime":{"text":"7 min read"}}},"site":{"siteMetadata":{"title":"JumpML"}}},"pageContext":{"slug":"/tutorial-pytorch-speechcommands-quantize/output/"}}}